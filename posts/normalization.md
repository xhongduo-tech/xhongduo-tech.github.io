## 从一张成绩单说起

期末考试，全班数学成绩如下：

```
小明：87  小红：92  小李：65  小王：99  小张：41
```

班级平均分是 **76.8 分**，最低 41 分，最高 99 分。

现在问你：小明的 87 分，算好还是不好？

光看这个数字你很难判断。但如果我告诉你：他比全班平均高了 10 分，处于班级前 25%——你立刻就有了感觉。

这个过程，就是**归一化（Normalization）**：把原始数据转换成一种更"标准"、更方便比较的形式。

统计上的标准做法叫 **Z-score 标准化**：

$$z = \frac{x - \mu}{\sigma}$$

其中 $x$ 是原始分数，$\mu$ 是平均分，$\sigma$ 是标准差。小明的 87 分变成：

$$z_{\text{小明}} = \frac{87 - 76.8}{16.7} \approx +0.61$$

正数说明高于平均，数字大小代表高出多少个"标准偏差"。所有人的分数都映射到了同一个可比较的尺度上。

**深度学习里的归一化，做的是完全相同的事情——只不过对象从学生变成了神经网络里的激活值。**

---

## 神经网络为什么需要归一化

### 先搞清楚激活值是什么

神经网络由一层一层的神经元堆叠而成。每层神经元接收上一层的输出，做一些计算，把结果传给下一层。这个"每层的输出"，就叫做**激活值（Activation）**。

```
输入层          第1层          第2层          ...         输出层
[1.2, 0.8]  →  [3.7, -2.1]  →  [0.2, 8.9]  →  ...  →  [预测结果]
               激活值          激活值
```

### 问题：激活值会"失控"

在没有任何约束的情况下，随着网络变深，激活值的分布会越来越不稳定：

```
第 1 层激活值：[-1, 0.5, 1.2, -0.3]   均值≈0，范围小
第 5 层激活值：[-8, 0.1, 12, -6]       均值偏了，范围变大
第10层激活值：[-500, 2, 900, -300]     完全失控
```

这会导致两个严重问题：

**问题一：梯度消失（Vanishing Gradients）**

神经网络用激活函数引入非线性，常见的 Sigmoid 函数长这样：

```
sigmoid(x) = 1 / (1 + e^(-x))

     1 |          ___________
       |        /
   0.5 |-------/
       |      /
     0 |_____/
       ------+-----+-----
           -5  0   5    x
```

当 $x$ 非常大（比如 500）或非常小（比如 -300）时，函数几乎是水平的——斜率接近 0。

梯度（斜率）是神经网络"学习"的信号。**斜率接近 0 = 没有学习信号 = 训练卡死**。这就是梯度消失问题。

**问题二：梯度爆炸（Exploding Gradients）**

反过来，如果激活值的尺度不断放大，梯度也会随之爆炸到极大的数值，导致参数更新时每一步都迈出巨大的一步——训练变得极不稳定，损失值来回振荡，无法收敛。

```
                   损失值
理想情况：  ↘↘↘↘↘↘↘↘  平稳下降
梯度爆炸：  ↘↗↘↗↘↗↘↗  来回振荡，无法收敛
```

### 归一化的作用

归一化把每层的激活值"拉回"到一个合理的范围内：

```
归一化前：  [-500, 2, 900, -300]   → 范围混乱
归一化后：  [-1.3, 0.01, 1.8, -0.8]  → 范围稳定
```

这样，无论网络有多深，每层看到的输入都在可预期的范围内，梯度能够稳定传播，训练才能顺利进行。

---

## 第一章：Batch Normalization——第一个成功的方案

2015 年，Google 的两位研究员发表了 **Batch Normalization（批量归一化，BatchNorm）** 的论文，它让深层神经网络的训练变得前所未有的稳定和快速。

### 批量（Batch）是什么

训练神经网络时，我们不是一次只看一个数据，而是每次取一小批（batch）数据一起计算。比如一个批量大小为 32 的 batch，里面有 32 张图片或 32 句话。

BatchNorm 的核心思想：**在每个批量内，对每个特征维度单独做归一化**。

### 公式拆解

设一个批量内某个特征的值为 $\{x_1, x_2, \ldots, x_N\}$（$N$ 是批量大小），BatchNorm 的计算步骤：

**第一步：计算批量均值**

$$\mu_B = \frac{1}{N} \sum_{i=1}^{N} x_i$$

**第二步：计算批量方差**

$$\sigma_B^2 = \frac{1}{N} \sum_{i=1}^{N} (x_i - \mu_B)^2$$

**第三步：归一化（加 $\epsilon$ 防止除以零）**

$$\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$$

**第四步：缩放和平移（让网络自行决定最终的分布）**

$$y_i = \gamma \cdot \hat{x}_i + \beta$$

其中 $\gamma$（scale，缩放）和 $\beta$（bias，偏移）是**可学习的参数**，由网络训练时自动学习。$\epsilon$ 是一个极小值（通常取 $10^{-5}$），防止方差为零时出现除以零的数值错误。

完整公式写在一起：

$$y = \gamma \cdot \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} + \beta$$

### 图示：BatchNorm 在做什么

想象一个 $4 \times 4$ 的数据矩阵（4 个样本，每个样本有 4 个特征）：

```
          特征1   特征2   特征3   特征4
样本1   [  8.2    0.1   -3.5    7.0  ]
样本2   [ -2.1    0.3    1.2    5.5  ]
样本3   [  5.5    0.0   -1.0    9.1  ]
样本4   [  1.4    0.2    2.3    6.2  ]
          ↑
    对这一列（特征1的4个样本）
    计算均值和方差，然后归一化
```

BatchNorm 对每一**列**（每个特征维度）分别计算该批量内的均值和方差，再归一化。

### 训练 vs 推理：一个微妙的差异

BatchNorm 在训练和推理时的行为不同：

- **训练时**：用当前批量的均值和方差
- **推理时**：用训练过程中累积的移动平均均值和方差

这个差异会造成一个隐患：如果训练时的批量分布和实际使用时的数据分布不一致，模型表现就会下降。

### BatchNorm 的局限性

BatchNorm 很强大，但有两个明显的弱点：

**弱点一：批量太小时失效**

当批量大小很小（比如只有 4 个样本），批量内的均值和方差就很不稳定——4 个样本根本代表不了整体分布。训练会变得不稳定。

**弱点二：序列模型（RNN/Transformer）很难用**

BatchNorm 需要在批量维度上求统计量。但在语言模型里，每条序列的长度不同，不同时间步的特征含义也不同，跨样本求均值没有意义。

这就引出了针对 Transformer 专门设计的归一化方法。

---

## 第二章：Layer Normalization——Transformer 的选择

**Layer Normalization（层归一化，LayerNorm）** 由 Ba 等人于 2016 年提出，它把 BatchNorm 的归一化维度做了一个简单但关键的旋转：

**BatchNorm**：跨多个样本，对同一个特征维度归一化（列方向）
**LayerNorm**：在单个样本内，对所有特征维度归一化（行方向）

### 图示：维度的旋转

```
          特征1   特征2   特征3   特征4
样本1   [  8.2    0.1   -3.5    7.0  ]  ← LayerNorm 对这一行求均值/方差
样本2   [ -2.1    0.3    1.2    5.5  ]  ← LayerNorm 对这一行求均值/方差
样本3   [  5.5    0.0   -1.0    9.1  ]  ← LayerNorm 对这一行求均值/方差
样本4   [  1.4    0.2    2.3    6.2  ]  ← LayerNorm 对这一行求均值/方差
          ↑每列
      BatchNorm 对这一列求均值/方差
```

每个样本独立计算，互不干扰。

### 公式

设单个样本的特征向量为 $x = [x_1, x_2, \ldots, x_D]$（$D$ 是特征维度，比如 Transformer 的 hidden size）：

**计算均值**：

$$\mu = \frac{1}{D} \sum_{i=1}^{D} x_i$$

**计算方差**：

$$\sigma^2 = \frac{1}{D} \sum_{i=1}^{D} (x_i - \mu)^2$$

**归一化 + 可学习的缩放和偏移**：

$$y = \gamma \cdot \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta$$

形式和 BatchNorm 完全一样，只是 $\mu$ 和 $\sigma^2$ 的计算范围变了——从跨样本变成了单样本内的所有特征。

### 为什么 LayerNorm 更适合 Transformer

**完全不依赖批量大小**：每个样本独立计算，批量大小为 1 和 1000 效果完全相同。

**训练和推理行为一致**：没有"训练用批量统计，推理用移动平均"的分裂，更稳定。

**天然适合变长序列**：不同长度的序列可以用同样的方式处理，不会互相干扰。

正因如此，原始 Transformer 论文（"Attention is All You Need"，2017）以及 BERT、GPT 系列都采用 LayerNorm。

---

## 第三章：RMSNorm——现代大模型的标配

LayerNorm 很好，但 2019 年，Zhang & Sennrich 的论文 *Root Mean Square Layer Normalization* 提出了一个问题：

**LayerNorm 里的均值减法，真的有必要吗？**

### 先理解 LayerNorm 在做什么

LayerNorm 的归一化步骤本质上做了两件事：

1. **去中心化（Re-centering）**：减去均值 $\mu$，让激活值的中心移到 0
2. **重新缩放（Re-scaling）**：除以标准差 $\sigma$，让激活值的尺度统一

作者提出假设：**去中心化可能是多余的**。神经网络本身有偏置（bias）参数，能够自己学会调整分布中心。Layer Normalization 里真正起稳定作用的，只是重新缩放这一步。

如果去掉均值减法，公式会简化到什么程度？

### RMS（均方根）

去掉均值之后，分母里的方差退化为一个更简单的量：**均方根（Root Mean Square，RMS）**。

$$\text{RMS}(x) = \sqrt{\frac{1}{D} \sum_{i=1}^{D} x_i^2}$$

这实际上就是把所有特征值平方后取平均，再开根号。它衡量的是向量的**整体"大小"或"能量"**，而不关心方向（均值）。

### RMSNorm 公式

$$\text{RMSNorm}(x) = \frac{x}{\text{RMS}(x) + \epsilon} \cdot \gamma$$

展开写：

$$y_i = \frac{x_i}{\sqrt{\dfrac{1}{D}\displaystyle\sum_{j=1}^{D} x_j^2 + \epsilon}} \cdot \gamma_i$$

和 LayerNorm 对比：

| | LayerNorm | RMSNorm |
|--|-----------|---------|
| **减去均值** | ✅ 是 | ❌ 否 |
| **除以标准差/RMS** | 标准差 $\sigma$ | RMS |
| **可学习参数** | $\gamma$（缩放）+ $\beta$（偏移） | 只有 $\gamma$（缩放） |
| **运算量** | 两遍扫描（先算均值，再算方差） | 一遍扫描（直接算 $x^2$） |

### 计算量为什么更少？

LayerNorm 需要**两遍**扫描特征向量：
1. 第一遍：计算均值 $\mu$
2. 第二遍：基于均值计算方差 $\sigma^2$

RMSNorm 只需要**一遍**：
1. 直接计算 $\sum x_i^2$，得到 RMS

在模型很大的情况下（比如 LLaMA-3 有 8 千亿参数），这个差异积累起来相当可观。实测 RMSNorm 比 LayerNorm 快 **7–15%**，在某些架构上甚至能快 30% 以上。

### 效果验证

论文实验表明：去掉均值减法之后，**模型的训练稳定性和最终效果与 LayerNorm 持平甚至略优**。这验证了假设：去中心化确实是多余的。

更简单、更快、效果不差——这就是 RMSNorm 迅速成为大模型标配的原因。

---

## 第四章：Pre-Norm vs Post-Norm——放在哪里同样重要

归一化放在 Transformer 层的哪个位置，对训练稳定性的影响不亚于用哪种归一化方法。

### 两种放置方式

**Post-Norm（后置归一化）**——原始 Transformer（2017）采用：

```
输入 x
  ↓
┌──────────────────────┐
│   Attention 计算      │
└──────────────────────┘
  ↓                 ↓ 残差连接
  └────────────────→ + ← x（原始输入）
                    ↓
              LayerNorm     ← 归一化在残差加法之后
                    ↓
              输出
```

**Pre-Norm（前置归一化）**——GPT-2 及之后的现代模型采用：

```
输入 x
  ↓
LayerNorm              ← 归一化在 Attention 之前
  ↓
┌──────────────────────┐
│   Attention 计算      │
└──────────────────────┘
  ↓                 ↓ 残差连接
  └────────────────→ + ← x（原始输入）
                    ↓
              输出
```

### 关键区别：残差路径的命运

Post-Norm 里，归一化作用在残差加法之后，也就是作用在了**残差连接的输出**上。这等于归一化层同时管控了主路径和跳跃连接——梯度流经归一化层时会被调整，深层网络中梯度尺度会随深度发生明显变化，训练不稳定。

Pre-Norm 里，残差连接直接把梯度**绕过**归一化层传递回去，梯度的主路径是未经扰动的：

```
梯度流动方向（反向传播）：

Post-Norm：  输出 → LayerNorm → (Attention + 残差) → 上一层
                          ↑
               归一化层修改了梯度尺度

Pre-Norm：   输出 → (Attention + 残差) → 上一层
                                ↑
                     残差路径直接透传，梯度尺度稳定
```

**结果**：Pre-Norm 可以用更大的学习率，不需要严格的预热（warmup），可以训练更深的网络。这是从 GPT-2 开始几乎所有大模型都改用 Pre-Norm 的原因。

---

## 第五章：其他归一化变体

### Group Normalization（组归一化）

在 BatchNorm 批量太小失效的场景（如目标检测，批量大小常常只有 2-4），GroupNorm 把特征通道分成若干组，在每组内独立归一化：

```
特征通道按组划分（4组，每组4个通道）：
[ch1, ch2, ch3, ch4 | ch5, ch6, ch7, ch8 | ...]
 ←── 第1组 ──────────→  ←── 第2组 ──────→
   在组内计算均值/方差         在组内计算均值/方差
```

**适用场景**：图像分割、目标检测等批量小但通道多的任务。

### Instance Normalization（实例归一化）

每个样本的每个通道单独归一化，常用于**风格迁移**——去掉图像的风格信息（亮度、对比度）、只保留内容特征：

```
输入图像 → 每个通道单独归一化 → 风格被"抹平" → 可与新风格融合
```

### 对比总结

```
          批量大小   适用模型        典型场景
BatchNorm  依赖大批量  CNN            图像分类、大批量训练
LayerNorm  完全无关   Transformer     GPT-2/3, BERT
RMSNorm    完全无关   Transformer     LLaMA, DeepSeek, Qwen
GroupNorm  完全无关   CNN             目标检测，小批量
InstanceNorm 完全无关  CNN            风格迁移
```

---

## 第六章：现代大模型都在用什么

最直接的证据：

| 模型 | 归一化方法 | 放置方式 |
|------|-----------|---------|
| GPT-2 | LayerNorm | Pre-Norm |
| GPT-3 | LayerNorm | Pre-Norm |
| BERT | LayerNorm | Post-Norm |
| LLaMA 1 / 2 / 3 | **RMSNorm** | Pre-Norm |
| Mistral | **RMSNorm** | Pre-Norm |
| DeepSeek-V2 / V3 | **RMSNorm** | Pre-Norm |
| Qwen 系列 | **RMSNorm** | Pre-Norm |

从 2023 年起发布的主流大模型，**几乎全部采用 RMSNorm + Pre-Norm 的组合**。

### 为什么在大模型里 RMSNorm 的优势更突出

以 LLaMA-3 70B 模型为例，它有 80 层 Transformer，每层都有两次归一化调用。如果每次归一化节省 10% 的时间，积累到整个模型训练周期（数百亿 token），节省的算力可以折合成数十万美元的计算成本。

简单就是力量。

---

## 完整公式对比

三个核心方法并排：

**BatchNorm**（对批量维度归一化）：

$$y = \gamma \cdot \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} + \beta$$

$$\mu_B = \frac{1}{N}\sum_{i=1}^N x_i \quad \sigma_B^2 = \frac{1}{N}\sum_{i=1}^N(x_i - \mu_B)^2$$

**LayerNorm**（对特征维度归一化）：

$$y = \gamma \cdot \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta$$

$$\mu = \frac{1}{D}\sum_{i=1}^D x_i \quad \sigma^2 = \frac{1}{D}\sum_{i=1}^D(x_i - \mu)^2$$

**RMSNorm**（去均值，只做重缩放）：

$$y = \gamma \cdot \frac{x}{\text{RMS}(x) + \epsilon}$$

$$\text{RMS}(x) = \sqrt{\frac{1}{D}\sum_{i=1}^D x_i^2}$$

三者的核心差异只在两个维度：
1. **归一化的范围**：批量维度 vs 特征维度
2. **是否去中心**：减均值 vs 不减均值

---

## 一个数值例子：RMSNorm 手动计算

设输入向量 $x = [3, -1, 4, -2]$（$D = 4$）：

**第一步：计算各元素平方**

$$x^2 = [9, 1, 16, 4]$$

**第二步：计算平均平方值**

$$\frac{1}{D}\sum x_i^2 = \frac{9+1+16+4}{4} = \frac{30}{4} = 7.5$$

**第三步：计算 RMS**

$$\text{RMS}(x) = \sqrt{7.5} \approx 2.739$$

**第四步：归一化**

$$\hat{x} = \frac{x}{\text{RMS}(x)} = \frac{[3, -1, 4, -2]}{2.739} \approx [1.095, -0.365, 1.461, -0.730]$$

**第五步：乘以可学习的 $\gamma$**（假设初始化为全 1）

$$y = 1 \cdot \hat{x} = [1.095, -0.365, 1.461, -0.730]$$

最终向量的 RMS 值：$\sqrt{(1.095^2 + 0.365^2 + 1.461^2 + 0.730^2)/4} \approx 1.0$

**归一化后向量的"能量"被统一到了 1 附近**，无论原始输入有多大或多小。

---

## 总结：归一化的本质

从成绩单的 Z-score，到 BatchNorm、LayerNorm，再到 RMSNorm，核心思想从未改变：

> **把激活值的尺度控制在合理范围内，让梯度能够稳定流动，让训练能够顺利进行。**

不同方法的演进，是在不断回答同一个问题：**最少做什么，才能达到这个目标？**

- BatchNorm：跨样本归一化，适合 CNN，但依赖批量大小
- LayerNorm：样本内归一化，适合 Transformer，彻底解耦批量
- RMSNorm：去掉多余的均值计算，只做缩放，更快、同样有效

现代大模型的选择给出了清晰的答案：**Pre-Norm + RMSNorm**，简单到极致，但足够强大。

理解了这条演进路径，你就掌握了理解 LLaMA、DeepSeek、Qwen 等主流模型架构的一块关键基石。
